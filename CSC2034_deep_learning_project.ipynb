{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSC2034-deep-learning-project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJTrBwuMKtcr",
        "outputId": "11c41c01-a167-4c19-af11-25b8897fd538"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "from datetime import datetime\n",
        "from tensorflow.core.protobuf import rewriter_config_pb2\n",
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from __future__ import print_function\n",
        "from keras import regularizers\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.datasets as datasets\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import datetime, os\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32, 32\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version:  2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3ESs1_3K2bE",
        "outputId": "59743172-aa03-4b1a-b282-6ddc7050b9e5"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (3, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_orig = y_test\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Uncomment these lines to enable the data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False)\n",
        " #compute quantities required for featurewise normalization\n",
        " #(std, mean, and principal components if ZCA whitening is applied)\n",
        "datagen.fit(x_train)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcD8CZh9H-Hk"
      },
      "source": [
        "rm -rf ./logs #clears model logs"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7MNN5mALTCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "b87ceb0a-bd80-47d8-d254-e07931e5c99e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs/final-model\".format())\n",
        "\n",
        "optimizer = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
        "  \n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "  \n",
        "''' \n",
        "def train_model(lr):\n",
        "  #This was used when running tests. \n",
        "\n",
        "  # resets the model \n",
        "  del model\n",
        "  K.clear_session()\n",
        "  tf.compat.v1.reset_default_graph()\n",
        "  \n",
        "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
        "  train_model(lr)\n",
        "'''  \n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\ndef train_model(lr):\\n  #This was used when running tests. \\n\\n  # resets the model \\n  del model\\n  K.clear_session()\\n  tf.compat.v1.reset_default_graph()\\n  \\nfor lr in [0.1, 0.01, 0.001, 0.0001]:\\n  train_model(lr)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joRKTPoIpcb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1477dc-d0da-4bff-e320-c044ec1fa10c"
      },
      "source": [
        "history = model.fit(x=x_train, \n",
        "                    y=y_train, \n",
        "                    epochs=170,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_test, y_test), \n",
        "                    callbacks=[tensorboard])\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(metrics.classification_report(y_test_orig, predicted_classes))\n",
        "print()\n",
        "print(metrics.confusion_matrix(y_test_orig, predicted_classes))\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/170\n",
            "782/782 [==============================] - 59s 34ms/step - loss: 1.8210 - accuracy: 0.4673 - val_loss: 1.5376 - val_accuracy: 0.5119\n",
            "Epoch 2/170\n",
            "782/782 [==============================] - 22s 29ms/step - loss: 1.1727 - accuracy: 0.6443 - val_loss: 1.1168 - val_accuracy: 0.6669\n",
            "Epoch 3/170\n",
            "782/782 [==============================] - 23s 29ms/step - loss: 0.9542 - accuracy: 0.7074 - val_loss: 1.2699 - val_accuracy: 0.6002\n",
            "Epoch 4/170\n",
            "287/782 [==========>...................] - ETA: 13s - loss: 0.8571 - accuracy: 0.7383"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MN1PXePFGVi"
      },
      "source": [
        "#view TensorBoard logs with graphs\n",
        "%tensorboard --logdir logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOnYwFGlN4_z"
      },
      "source": [
        "img_index = 42\n",
        "image = x_test[img_index]\n",
        "\n",
        "pred=model.predict(np.expand_dims(image, axis=0))[0]\n",
        "for cl in range(num_classes):\n",
        "        print(\"Probability for class {}: {}\".format(cl,pred[cl]))\n",
        "print(\"\\nThe winner is {}\".format(np.argmax(pred)))\n",
        "print(\"The correct class is {}\\n\".format(np.argmax(y_test[img_index])))\n",
        "\n",
        "plt.imshow(image.squeeze(),cmap='viridis')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}